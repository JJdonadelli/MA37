\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}

\begin{document}

Suponha que desejamos estudar como o comportamento muda sob certas condições experimentais. Pensamos, em particular, em uma sequência de eventos começando com a percepção de um estímulo, seguida pela execução de uma resposta (pressionar uma barra, correr em um labirinto, etc.), e terminando com a ocorrência de um evento ambiental (apresentação de comida, choque elétrico, etc.):

O comportamento é medido pela probabilidade $p$ de que a resposta ocorra durante um determinado intervalo de tempo após o início da sequência. A ideia geral é que $p$ denote o nível de desempenho do sujeito e seja aumentada ou diminuída após cada ocorrência da resposta, conforme os fatores ambientais sejam reforçadores ou inibidores.

Se imaginarmos um experimento no qual um sujeito é repetidamente exposto a essa sequência de eventos (estímulo–resposta–evento ambiental), podemos dividir o experimento em estágios, cada estágio sendo uma tentativa durante a qual o sujeito percorre a sequência. O nível de desempenho do sujeito é então uma função do número de tentativas, denotado por $n$, e seja $p$ a probabilidade da resposta (durante o intervalo de tempo especificado após o estímulo) na $n$-ésima tentativa.

O número $p_0$ será tomado como o valor inicial que descreve a disposição do sujeito em relação à resposta quando ele é introduzido no experimento propriamente dito. A função $p$ é então definida no domínio do conjunto de valores $n = 0, 1, 2, \ldots$. Ao chamar $p$ de uma probabilidade, impomos a normalização:

\begin{equation}
0 \leq p \leq 1, \quad n = 0, 1, 2, \ldots
\tag{2.95}
\end{equation}

o que apenas identifica os extremos de nenhuma resposta e resposta certa com os valores 0 e 1, respectivamente.

Assumimos inicialmente que $p_{n+1}$ depende apenas de $p_n$ e não dos valores anteriores da função $p$. Em outras palavras, o desempenho do sujeito na tentativa $n+1$, embora dependente do nível de comportamento na tentativa anterior (medido por $p_n$), é independente do histórico completo até a tentativa $n$. Isso é conhecido como a propriedade de Markov do modelo.

Seguindo Bush e Mosteller, fazemos a suposição simplificadora de que essa dependência de $p_{n+1}$ em relação a $p_n$ é linear, ou seja, uma linha reta resulta quando $p_{n+1}$ é representada graficamente como função de $p_n$. A forma de inclinação e intercepto dessa equação é:

\begin{equation}
p_{n+1} = a + m p_n, \quad n = 0, 1, 2, \ldots
\tag{2.96}
\end{equation}

onde $a$ é o intercepto (isto é, o valor de $p_{n+1}$ quando $p_n = 0$) e $m$ é a inclinação da linha (isto é, a variação em $p_{n+1}$ por unidade de variação de $p_n$).

Para nossos propósitos, é mais conveniente escrever essa relação linear na forma de ``ganho-perda''. Introduzimos o parâmetro $b$ pela equação definidora:

\begin{equation}
m = 1 - a - b
\tag{2.97}
\end{equation}

Assim, a relação 2.96 pode ser reescrita como:

\begin{equation}
p_{n+1} = p_n + a(1 - p_n) - b p_n, \quad n = 0, 1, 2, \ldots
\tag{2.98}
\end{equation}

\noindent
Nota: se conhecemos os valores de $a$ e $m$, então $b$ é unicamente determinado pela equação {2.97}; se $a$ e $b$ são conhecidos, também podemos determinar $m$.


Assim, as equações (2.96) e (2.98) são formas alternativas, mas equivalentes, da relação linear entre $p$ e $p_{n+1}$.

Se o nível de desempenho do sujeito na tentativa de número $n$ é dado por $p$, então $1 - p$ é o aumento máximo possível de desempenho e $-p$ é a diminuição máxima possível ao passar para a tentativa $n + 1$. Isso decorre do fato de que 1 e 0 são os maiores e menores valores possíveis de probabilidade. 

A equação (2.98) pode ser interpretada dizendo que a mudança no nível de desempenho, $\Delta p = p_{n+1} - p_n$, é proporcional ao ganho máximo possível e à perda máxima possível. Por esse motivo, a equação (2.98) é chamada de forma “ganho-perda”. As constantes de proporcionalidade são $a$ e $b$, e podemos, portanto, medir com o parâmetro $a$ os eventos ambientais que são reforçadores (por exemplo, apresentação de uma recompensa) e com $b$ os eventos que são inibidores (por exemplo, punição ao sujeito).

As restrições sobre $a$ e $b$ são impostas apenas para garantir que, não importa qual seja o valor de $p$, consistente com (2.95), o valor seguinte $p_{n+1}$ também estará entre 0 e 1 inclusive. 

Se $p = 0$, então $p_{n+1} = a$, de modo que exigimos:
\begin{equation}
0 \leq a \leq 1.
\tag{2.99}
\end{equation}

Se $p = 1$, então $p_{n+1} = 1 - b$, e, portanto, requeremos:
\begin{equation}
0 \leq b \leq 1.
\tag{2.100}
\end{equation}

Mostramos que as condições (2.99) e (2.100) são necessárias para que $p_{n+1}$ esteja entre 0 e 1. Não é difícil mostrar que essas condições também são suficientes (ver Problema 1 da Seção 2.10). Essas são as únicas restrições impostas sobre os parâmetros $a$ e $b$ na equação fundamental de diferenças (2.98).

Assim, $a = 0$ descreve uma situação na qual nenhuma recompensa é dada após a resposta ocorrer, $b = 0$ descreve uma tentativa sem punição, e $a = b$ implica que as medidas de recompensa e punição são iguais.

Citamos Bush e Mosteller: “podemos agora descrever a mudança progressiva na probabilidade de uma resposta em um experimento como o de Graham-Gagné (pista de corrida) ou a caixa de Skinner, nos quais os mesmos eventos ambientais seguem cada ocorrência da resposta.”

Vamos considerar um exemplo específico: se $a = 0{,}4$ e $b = 0{,}1$, então a equação (2.98) torna-se:
\begin{align*}
p_{n+1} &= p_n + 0{,}4(1 - p_n) - 0{,}1p_n \\
        &= 0{,}5p_n + 0{,}4
\tag{2.101}
\end{align*}

Se assumirmos $p_0 = 0{,}2$, podemos calcular sucessivamente:
\begin{align*}
p_1 &= 0{,}5(0{,}2) + 0{,}4 = 0{,}5, \\
p_2 &= 0{,}5(0{,}5) + 0{,}4 = 0{,}65.
\end{align*}

Para resolver a equação (2.101) e obter $p_n$ para todo $n$, usamos o Teorema 2.7 com $A = 0{,}5$, $B = 0{,}4$. O limite $p$ é dado por:
\begin{equation}
p = \frac{B}{1 - A} = \frac{0{,}4}{1 - 0{,}5} = 0{,}8.
\end{equation}

A solução geral é então:
\begin{equation}
p_n = (0{,}5)^n(p_0 - 0{,}8) + 0{,}8.
\tag{2.102}
\end{equation}

Essa solução mostra exatamente como o nível de desempenho varia com o número de tentativas. Como $0 < A < 1$ e $p_0 < p$, sabemos (ver Tabela 2.2) que a sequência $\{p_n\}$ é monótona crescente com limite $p = 0{,}8$.

Assim, para tentativas repetidas em que recompensa e punição têm peso na razão 4:1 (como em $a = 0{,}4$ e $b = 0{,}1$), as probabilidades de resposta e de não resposta, $p$ e $1 - p$, se aproximam de valores limites cuja razão é a mesma.

Voltando ao caso geral, notamos que (2.98) pode ser reescrita na forma padrão:
\begin{equation}
p_{n+1} = (1 - a - b)p_n + a, \quad n = 0, 1, 2, \ldots
\tag{2.103}
\end{equation}

Reconhecemos essa equação como uma equação de diferenças linear de primeira ordem com coeficientes constantes. De fato, usando a notação do Teorema 2.7, temos:
\[
A = 1 - a - b, \quad B = a,
\]
e, portanto, o valor limite $p$ é:
\begin{equation}
p = \frac{B}{1 - A} = \frac{a}{a + b}, \quad \text{se } a + b \neq 0.
\tag{2.104}
\end{equation}

Temos então a solução geral:
\begin{equation}
p_n = 
\begin{cases}
(1 - a - b)^n(p_0 - p) + p, & \text{se } a + b \neq 0, \\
p_0, & \text{se } a + b = 0,
\end{cases}
\tag{2.105}
\end{equation}

À luz das condições (2.99) e (2.100), a constante $A = 1 - a - b$ está entre $-1$ e $1$, com os extremos atingidos apenas se $a$ e $b$ forem ambos iguais a 0 ou ambos iguais a 1.

Se $a = b = 1$, então $A = -1$ e a sequência $\{p_n\}$ oscila finitamente entre os valores $p_0$ e $1 - p_0$. Mas em todos os outros casos a sequência $\{p_n\}$ converge, para o limite $p_0$ se $a = b = 0$, e para o limite $p$ caso contrário.

Se $0 < a + b < 1$, então $0 < A < 1$ e $\{p_n\}$ é monótona:
\begin{itemize}
  \item decrescente, se $p_0 > p$,
  \item crescente, se $p_0 < p$,
  \item constante, se $p_0 = p$.
\end{itemize}

Se $1 < a + b < 2$, então $-1 < A < 0$ e $\{p_n\}$ é uma sequência oscilatória amortecida com limite $p$. O caso especial $a + b = 0$ gera uma sequência constante (com valor $p_0$), e $a + b = 1$ gera uma sequência em que todos os elementos são iguais a $p$.

\section*{Casos Especiais}

Concluímos com dois casos especiais:
\begin{enumerate}
  \item $a = 0$
  \item $a = b$
\end{enumerate}

\textbf{Caso (1)}: Assume-se que nenhuma recompensa é dada após a ocorrência da resposta. A equação de diferenças (2.98) torna-se:

\begin{equation}
p_{n+1} = (1 - b)p_n
\end{equation}

com solução:

\begin{equation}
p_n = (1 - b)^n p_0, \quad n = 0, 1, 2, \ldots
\end{equation}

Esta é uma equação que descreve a diminuição constante da probabilidade de resposta (à medida que $n \to \infty$) a partir da probabilidade inicial $p_0$. Ao representar $p$ como função de $n$, obtemos uma curva de extinção experimental (ver discussão no Capítulo 0, Exemplo 1).

\textbf{Caso (2)}: Quando $a = b$, as medidas de reforço e punição são iguais. Descartando os casos extremos $a = b = 0$ e $a = b = 1$, temos que a quantidade $(1 - a - b) \to 0$ conforme $n \to \infty$, e a equação (2.105) mostra que o limite de $p_n$ é:

\[
p = \frac{a}{a + b} = \frac{a}{2a} = \frac{1}{2}.
\]

Ou seja, a resposta tende a ocorrer (no intervalo de tempo especificado após o estímulo) em metade das tentativas. O equilíbrio entre forças de recompensa e punição produz, no longo prazo, uma simetria correspondente no desempenho.

\vspace{1em}

\section*{Problemas 2.10}

\begin{enumerate}
  \item Se $p_{n+1} = p_n + a(1 - p_n) - b p_n$ e $0 \leq p_n \leq 1$, mostre que, se $0 \leq a \leq 1$ e $0 \leq b \leq 1$, então também $0 \leq p_{n+1} \leq 1$. \\
  \textbf{[Dica:} Estabeleça as desigualdades: \\
  $p + a(1 - p) - bp \leq p + 1(1 - p) - 0 = 1$, quando $p = 0$; \\
  $p + a(1 - p) - bp \geq p + 0(1 - p) - p = 0$, quando $p = 1$.]

  \item Usando a equação (2.98) com $a = 0{,}5$ e $b = 0{,}2$, calcule os valores de $p_{n+1}$ para:
  \[
  p_n = 0,\ 0{,}1,\ 0{,}2,\ \ldots,\ 0{,}9,\ 1
  \]
  e trace o gráfico da reta, com $p_n$ no eixo horizontal e $p_{n+1}$ no eixo vertical.

  \item 
  \begin{enumerate}
    \item Resolva a equação de diferenças (2.98) no caso $p_0 = 0{,}5$, $a = 0{,}1$, e $b = 0{,}4$, e mostre que, quando as medidas de reforço e punição estão na razão 1:4, as probabilidades limites de resposta e não resposta estão na mesma razão.
    \item Generalize esse resultado mostrando que, quando as medidas de reforço e punição estão na razão $a:b$, as probabilidades limites de resposta e não resposta estão na mesma razão.
  \end{enumerate}

  \item Com $n$ no eixo horizontal e $p_n$ no eixo vertical, trace os gráficos da função $p_n$ nos seguintes casos:
  \begin{enumerate}
    \item $a = 0,\ b = 0{,}2$
    \item $a = 0,\ b = 0{,}5$
    \item $a = 0,\ b = 0{,}8$
  \end{enumerate}
  Suponha $p_0 = 0{,}5$ e mostre que quanto maior for $b$, mais rapidamente $p_n \to 0$.

  \item Repita o problema anterior com $p_0 = 0{,}5$, mas agora:
  \begin{enumerate}
    \item $a = 0{,}2,\ b = 0$
    \item $a = 0{,}5,\ b = 0$
    \item $a = 0{,}8,\ b = 0$
  \end{enumerate}
\end{enumerate}

\end{document}




